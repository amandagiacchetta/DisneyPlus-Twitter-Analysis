{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API v1.1 Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth_twitter():\n",
    "        \n",
    "    consumer_key= 'drhztkGNhICDt3cwBGXi7zzQk'\n",
    "    consumer_secret= 'FDeCBlSi4qIbR9oPsf3tphQjCO6HqZfYANWceYIdJDZHsOaabi'\n",
    "    access_token= '207778119-E9W1kqRXBbNeU2n8vcA0OoMn9XZpE9yvmZrD8gUx'\n",
    "    access_token_secret= 'dncbYQQrh5jlJ97OmgxeaGgqOFiC7jnNpXdPngWMCRtDE'\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    return api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query API V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_tweets(api, search_words, until, lang, items):\n",
    "\n",
    "        ##search_words = \"DisneyPlus\"\n",
    "        ##until= \"2020-11-03\"\n",
    "        ##lang = 'pt'\n",
    "\n",
    "        cursor = tweepy.Cursor(api.search,\n",
    "                    q=search_words,\n",
    "                    lang=lang,\n",
    "                    until= until, count=100).items(items)\n",
    "\n",
    "        return cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cursor to List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterator_to_list(cursor):\n",
    "\n",
    "    return list(cursor)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tweets_to_dataframe(tweets_list):\n",
    "\n",
    "    columns = set()\n",
    "    \n",
    "    tweets_data = []\n",
    "\n",
    "    \n",
    "    for tweet in tweets_list:\n",
    "        keys = tweet._json.keys()\n",
    "        single_data = {}\n",
    "        \n",
    "        \n",
    "        for k in keys:\n",
    "\n",
    "\n",
    "            if tweet._json.get(k) == None:\n",
    "\n",
    "                try:\n",
    "\n",
    "                    single_data[k] = 0\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                \n",
    "            \n",
    "            else:\n",
    "              \n",
    "               try:\n",
    "                    single_data[k] = tweet._json.get(k)\n",
    "               \n",
    "               except Exception as e:\n",
    "                    print(e)\n",
    "                    single_data[k] = 0\n",
    "\n",
    "                \n",
    "            \n",
    "            columns.add(k)\n",
    "\n",
    "        tweets_data.append(single_data)    \n",
    "    \n",
    "\n",
    "    header_cols = list(columns)\n",
    "    df = pd.DataFrame(tweets_data, columns=header_cols)\n",
    "    df.head()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entities column: finding mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentions(df):\n",
    "\n",
    "        df['screen_name_mention_1'] = df['entities'].apply(lambda x: x['user_mentions'][0]['screen_name'] if x['user_mentions'] else None)\n",
    "\n",
    "        df['id_mention_1'] = df['entities'].apply(lambda x: x['user_mentions'][0]['id_str'] if x['user_mentions'] else 0)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retweeted_Status - Finding the author of the original tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retweets(df):\n",
    "\n",
    "    df['retweeted_from_screen_name'] = df['retweeted_status'].apply(lambda x: x['user']['screen_name'] if x is not np.nan else None)\n",
    "\n",
    "    df['retweeted_from_id'] = df['retweeted_status'].apply(lambda x: x['user']['id_str'] if x is not np.nan else 0)\n",
    "\n",
    "    df['retweeted_from_is_verified'] = df['retweeted_status'].apply(lambda x: x['user']['verified'] if x is not np.nan else None)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User - Information about the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user(df):\n",
    "\n",
    "    df['user_screen_name'] = df['user'].apply(lambda x: x['screen_name'] if x is not np.nan else None)\n",
    "\n",
    "    df['user_id'] = df['user'].apply(lambda x: x['id_str'] if x is not np.nan else 0)\n",
    "\n",
    "    df['user_followers'] = df['user'].apply(lambda x: x['followers_count'] if x is not np.nan else None)\n",
    "\n",
    "    df['user_following'] = df['user'].apply(lambda x: x['friends_count'] if x is not np.nan else None)\n",
    "\n",
    "    df['user_is_verified'] = df['user'].apply(lambda x: x['verified'] if x is not np.nan else None)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New Columns\n",
    "\n",
    "def destrinchando_colunas(df):\n",
    "    \n",
    "    mentions(df)\n",
    "    retweets(df)\n",
    "    user(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formating Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_created_at(df):\n",
    "\n",
    "    df['created_at'] = df['created_at'].apply(lambda x: datetime.strptime(x,'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(df, file_name):\n",
    "    \n",
    "    df.to_csv(f'C:/Users/amand/Documents/Jupyter Notebooks/DisneyPlus/data_final_csv/{file_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pickle(df, file_name):\n",
    "\n",
    "    df.to_pickle(f'C:/Users/amand/Documents/Jupyter Notebooks/DisneyPlus/data_final_pkl/{file_name}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(df):\n",
    "\n",
    "    important_columns = ['user_screen_name', 'user_id', 'user_is_verified', 'retweeted_from_screen_name', 'retweeted_from_id', 'retweeted_from_is_verified', 'screen_name_mention_1' , 'id_mention_1', 'in_reply_to_screen_name', 'in_reply_to_user_id', 'created_at', 'id', 'text', 'retweet_count', 'favorite_count', 'user_followers','user_following']\n",
    "\n",
    "    df = df[important_columns]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns_graph_ids(df):\n",
    "\n",
    "    graph_columns_ids = ['user_id', 'retweeted_from_id' , 'id_mention_1', 'in_reply_to_user_id',  'id']\n",
    "\n",
    "    df = df[graph_columns_ids]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo o processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pega_tweets(search_words, until, lang, items, file_name):\n",
    "\n",
    "    api = get_auth_twitter()\n",
    "\n",
    "    cursor = search_for_tweets(api, search_words, until, lang, items)\n",
    "\n",
    "    tweets_list = iterator_to_list(cursor)\n",
    "\n",
    "    df = tweets_to_dataframe(tweets_list)\n",
    "    df = destrinchando_colunas(df)\n",
    "    df = format_created_at(df)\n",
    "\n",
    "    create_csv(df, file_name)\n",
    "    create_pickle(df, file_name)\n",
    "   \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pega_tweets_filtrado(search_words, until, lang, items, file_name):\n",
    "\n",
    "    \n",
    "    api = get_auth_twitter()\n",
    "    \n",
    "    cursor = search_for_tweets(api, search_words, until, lang, items)\n",
    "\n",
    "    tweets_list = iterator_to_list(cursor)\n",
    "\n",
    "    df = tweets_to_dataframe(tweets_list)\n",
    "    df = destrinchando_colunas(df)\n",
    "    df = format_created_at(df)\n",
    "    df = filter_columns (df)\n",
    "\n",
    "    create_csv(df, file_name)\n",
    "    create_pickle(df, file_name)\n",
    "   \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Name: DisneyPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pega_tweets_filtrado(\"DisneyPlus\", \"\", \"pt\", 15000, 'until_18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.sort_values of 0       2020-11-18 13:26:19\n",
       "1       2020-11-18 13:26:16\n",
       "2       2020-11-18 13:26:16\n",
       "3       2020-11-18 13:26:09\n",
       "4       2020-11-18 13:26:00\n",
       "                ...        \n",
       "14995   2020-11-17 22:46:21\n",
       "14996   2020-11-17 22:46:18\n",
       "14997   2020-11-17 22:46:11\n",
       "14998   2020-11-17 22:46:10\n",
       "14999   2020-11-17 22:46:10\n",
       "Name: created_at, Length: 15000, dtype: datetime64[ns]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.created_at.sort_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
