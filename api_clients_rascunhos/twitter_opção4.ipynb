{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Autenticação "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'drhztkGNhICDt3cwBGXi7zzQk'\n",
    "consumer_secret= 'FDeCBlSi4qIbR9oPsf3tphQjCO6HqZfYANWceYIdJDZHsOaabi'\n",
    "access_token= '207778119-E9W1kqRXBbNeU2n8vcA0OoMn9XZpE9yvmZrD8gUx'\n",
    "access_token_secret= 'dncbYQQrh5jlJ97OmgxeaGgqOFiC7jnNpXdPngWMCRtDE'\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n"
   ]
  },
  {
   "source": [
    "## Query API V1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search term and the date_since date as variables\n",
    "search_words = \"DisneyPlus\"\n",
    "date_since = \"2020-11-03\"\n",
    "\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"pt\",\n",
    "              since=date_since).items(100)"
   ]
  },
  {
   "source": [
    "## Resultados: Cursor to List"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = list(tweets)"
   ]
  },
  {
   "source": [
    "## Extract DataFrame original"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timeline_as_df(timeline_list):\n",
    "    columns = set()\n",
    "    allowed_types = [str, int]\n",
    "    tweets_data = []\n",
    "    for status in timeline_list:\n",
    "        status_dict = dict(vars(status))\n",
    "        keys = status_dict.keys()\n",
    "        single_tweet_data = {\"user\": status.user.screen_name, \"author\": status.author.screen_name}\n",
    "        for k in keys:\n",
    "            try:\n",
    "                v_type = type(status_dict[k])\n",
    "            except:\n",
    "                v_type = None\n",
    "            if v_type != None:\n",
    "                if v_type in allowed_types:\n",
    "                    single_tweet_data[k] = status_dict[k]\n",
    "                    columns.add(k)\n",
    "        tweets_data.append(single_tweet_data)\n",
    "\n",
    "\n",
    "    header_cols = list(columns)\n",
    "    header_cols.append(\"user\")\n",
    "    header_cols.append('author')\n",
    "    df = pd.DataFrame(tweets_data, columns=header_cols)\n",
    "    return df"
   ]
  },
  {
   "source": [
    "## Extract DataFrame modificado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets(tweets_originais):\n",
    "\n",
    "    # Filtra os dados que eu vou tirar\n",
    "    columns = set()\n",
    "    allowed_types = [str, int]\n",
    "\n",
    "    #vai virar uma lista de dicionários que vai ser transformada em df\n",
    "    tweets_data = []\n",
    "\n",
    "\n",
    "    for cada_tweet in tweets_originais:\n",
    "        #transforma cada_tweet em um dicionario\n",
    "        cada_tweet_dict = dict(vars(cada_tweet))\n",
    "        #Acha a lista de keys que tem em cada_tweet\n",
    "        keys = cada_tweet_dict.keys()\n",
    "        #Cria um dicionario com duas chaves que não tem na lista acima, e ja coloca o conteúdo nelas\n",
    "        single_tweet_data = {\"screen_name\": cada_tweet.user.screen_name,  \n",
    "        \"user_id\": cada_tweet.user.id, \n",
    "        \"verified\":cada_tweet.user.verified, \n",
    "        \"followers\": cada_tweet.user.followers_count, \n",
    "        \"following\": cada_tweet.user.friends_count, \n",
    "        'created_at': cada_tweet.created_at, \n",
    "        'mentions':cada_tweet.entities['user_mentions'],\n",
    "        'retweets': cada_tweet.retweeted_status.user}\n",
    "\n",
    "        for k in keys:\n",
    "\n",
    "            try:\n",
    "                #Define o tipo de conteúdo dentro da chave\n",
    "                v_type = type(cada_tweet_dict[k])\n",
    "\n",
    "            except:\n",
    "                # Se o tipo de conteúdo for nulo, ou seja, o trem de cima não funcionar, coloca ele como None\n",
    "                v_type = None\n",
    "\n",
    "            #Depois de definir o tipo de conteúdo para uma chave k, vamos fazer alguma coisa com ele\n",
    "            if v_type != None:\n",
    "                #Então, se o conteúdo da chave tiver dos tipos permitidos\n",
    "\n",
    "                if v_type in allowed_types:\n",
    "                    #Vamos adicionar este conteúdo no dicionário criado lá em cima\n",
    "                    single_tweet_data[k] = cada_tweet_dict[k]\n",
    "\n",
    "                    columns.add(k)\n",
    "\n",
    "        #Adiciona o dicionário final criado a uma lista            \n",
    "        tweets_data.append(single_tweet_data)\n",
    "\n",
    "    #Transforma as colunas que estavam em forma de set em lista\n",
    "    header_cols = list(columns)\n",
    "    #Adiciona o chave user, já que ele tá fora das chaves principais\n",
    "    header_cols.append(\"screen_name\")\n",
    "    header_cols.append(\"user_id\")\n",
    "    header_cols.append(\"verified\")\n",
    "    header_cols.append(\"followers\")\n",
    "    header_cols.append(\"following\")\n",
    "    header_cols.append('created_at')\n",
    "    header_cols.append('mentions')\n",
    "    header_cols.append('retweets')\n",
    "    \n",
    "    #Cria o dataframe\n",
    "    df = pd.DataFrame(tweets_data, columns=header_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets2(tweets_originais):\n",
    "\n",
    "    # Filtra os dados que eu vou tirar\n",
    "    columns = set()\n",
    "\n",
    "    #vai virar uma lista de dicionários que vai ser transformada em df\n",
    "    tweets_data = []\n",
    "\n",
    "\n",
    "    for cada_tweet in tweets_originais:\n",
    "        #Acha a lista de keys que tem em cada_tweet\n",
    "        keys = cada_tweet._json.keys()\n",
    "        single_data = {}\n",
    "\n",
    "        for k in keys:\n",
    "            try:\n",
    "                cada_tweet._json.get(k)\n",
    "                single_data[k] = cada_tweet._json.get(k)\n",
    "\n",
    "            except:\n",
    "                single_data[k] = np.nan\n",
    "\n",
    "            columns.add(k)\n",
    "        \n",
    "\n",
    "        #Adiciona o dicionário final criado a uma lista            \n",
    "        tweets_data.append(single_data)\n",
    "\n",
    "\n",
    "    #Transforma as colunas que estavam em forma de set em lista\n",
    "    header_cols = list(columns)\n",
    "    \n",
    "    #Cria o dataframe\n",
    "    df = pd.DataFrame(tweets_data, columns=header_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'Cursor' object is not iterable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-1c5dbcd5337e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtweets_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_json\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msingle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Cursor' object is not iterable"
     ]
    }
   ],
   "source": [
    "## Funcao final\n",
    "\n",
    "columns = set()\n",
    "  \n",
    "tweets_data = []\n",
    "  \n",
    "for tweet in todos:\n",
    "    keys = tweet._json.keys()\n",
    "    single_data = {}\n",
    "      \n",
    "      \n",
    "    for k in keys:\n",
    "        try:\n",
    "            single_data[k] = tweet._json.get(k)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            single_data[k] = np.nan\n",
    "            \n",
    "        columns.add(k)\n",
    "    tweets_data.append(single_data)    \n",
    "  \n",
    "\n",
    "header_cols = list(columns)\n",
    "df = pd.DataFrame(tweets_data, columns=header_cols)\n",
    "df.head()\n",
    " \n",
    "df.to_csv(r'C:\\Users\\amand\\Documents\\Jupyter Notebooks\\DisneyPlus\\Data\\Teste1000_2.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.0 64-bit ('disneyplus': conda)",
   "display_name": "Python 3.8.0 64-bit ('disneyplus': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6e8d50762252da5a05abcadd322ec1792202d61bdb34674a0f4cb85c81b89e09"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}